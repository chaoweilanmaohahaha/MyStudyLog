# 锁与进程间通信

对于一个支持多任务的操作系统而说，既要保证每一个进程在运行的过程中是独立的，也要保护它们操作的数据，使得系统的运行稳定。那么我们就需要考虑数据是如何从一个进程传递给另一个进程的；数据是如何被共享的；进程如何等待对方；又是怎么分配占用的资源的。本内容就是围绕解决这些问题所展开的。

## 控制机制

首先我们看一下进程间在交互的过程中会出现什么问题。简单来说，如果两个进程在操作一个公用资源，比如文件数等，如果处理不当则会造成这样的数据丢失等情况。**那么当多个进程在进入某个资源的时候存在互相的干涉时，我们把这种情况称为竞态。**这也是分布时应用需要解决的一大核心问题。

从本质上来看，当进程在某个时间点被中断，那么它们在接下去所做的原本是对的，但是中断之后就不一定正确了（比如被操作的数据发生了变化）。那么是否可以在它做事的时候屏蔽所有中断呢？这是不现实的，这样很明显会让执行效率变差。

### 临界区

哦，那么最好的一种方法是什么呢？那就是使用一个区域，如果进程进入这片区域，那么其他进程是根本进不来的，除非上一个进程出去了。那么就算临界区内的进程被中断了，外面的进程也别想进去。这个设计固然是好的，但是在设计的时候也要考虑一些问题，比如考量进程的数量以及运行的速度，比如要保证进程不能永远被堵塞在外面。

### 信号量

信号量是在1965年由迪杰斯特拉提出的，它的提出用来解决进程间的通信问题。信号量的设计非常简单，它需要一个受到保护的变量，和两个简单的操作。对应这两个操作就会有两种情形：

* down：当一个进程需要进入某个代码区时先要让变量减1，如果此时的变量已经为0了，则进程需要阻塞在这个信号量上等待里面的进程退出

* up：当一个进程从某个代码区域退了出来，需要返还资源的时候，会让变量加1，然后唤醒其中一个进程（做down）。

这里要保证的是，其中的加1和减1操作均为原子的，也就是不能被打断的。所以这个过程肯定需要借助内核来完成。但是有趣的是，信号量实现非常简单，但是它的使用开销非常大（进程上下文的切换），所以你在系统中看到的大多使用其他的机制。

## 锁机制

来看一下这个场景哦，如果现在处于内核态，多处理器的情况下多个进程同时进入了一个相同的数据结构中修改其中的数据，这会导致竞态的产生。

内核中会使用加锁的方式杜绝一些问题的发生，常见的加锁的方法有：

* 原子操作：一般用在计数器身上，保证加减都是原子的；
* 自旋锁：用在一片较小的区域内；
* 信号量：比如Mutex就是一个非常特殊的信号量；
* 读写锁：针对读写问题而满足其需求所设计的锁；

### 原子操作

如果你在数据结构中看到由atomic_t开头而定义的数，说明它就是包含原子操作锁的数据。一般而言这个数据就是简单的类似整数等等这样的数据。这个操作的实现需要借助单独CPU汇编级指令的操作，但是它要保证平台的无关性，所以在内核中会给出一系列的方法有（以atomic_开头），来操作数据。

### 自旋锁

自旋锁经常是用来保护一些较短的代码区域的，因为使用它有个前提，就是要快速执行快速退出，许多数据结构在其中有它们自己的自旋锁。自旋锁的数据都是以spinlock_t定义的，操作它的方法包括spin_lock和spin_unlock。那么在实际应用中，如果在一个进程想要进入一片代码区时，如果当前这个区域的锁没有被其他进程拿到，那么就由当前进程获取锁；否则在执行spin_lock想要获得锁的操作上，当前的进程会陷入无尽的循环，直到使用锁的进程把锁归还了。这里可以看到的是，等待锁的过程只是在执行循环并没有牵涉到进程切换，所以它是轻量级的，但是在使用时还是要保证不能占用太长时间的锁，包括里面的进程不能在占有锁的情况下睡眠，这样很容易导致死锁。

### 信号量

在内核中使用的信号量一般定义为：

```
struct semaphore {
    atomic_t count;
    int sleepers;
    wait_queue_head_t wait;
};
```

那么count就是所谓的变量，可以看到它被定义为了原子级操作的整数。sleepers表示了想要这个信号量而阻塞在这里的进程。wait是该信号量的阻塞队列（TASK_UNINTERRUPTIBLE）。

### RCU机制

RCU机制的全称为read-copy-update，读-拷贝-更新。使用这个机制有那么些前提：

1. 这些区域一般大多都只读，很少涉及写操作；
2. 在使用RCU的过程中内核不能被阻塞；
3. 被保护的资源必须使用指针获取。

实现上也不难，简单的说，它需要跟踪所有指向这个共享结构的指针，这些进程都是在做读操作，随后如果一个进程导致了某个结构的变化，就复制这一个结构然后保留当前这个副本，只有在检测到所有读操作都已经完成时才将这个副本更新上去。在内核中的所有与rcu机制相关的操作名字都会带上rcu。

### 阻碍优化

这个方法是主要针对类似指令重排序这样的优化方案的。执行重排序可以提高执行性能，但是它没法保证必然的时序。那么在一些特定的地方，内核需要保证处理器不能进行指令重排序，也就是添加对优化的阻碍。比如使用mb，rmb，wmb方法等等。这些方法会使得程序的执行效率降低，但是这也是为了保证执行的正确性而做的牺牲。

### 读写锁

那么有会遇到这个情况，该资源允许多个进程同时进入读取，但是只允许一个进程对其进行修改，而读写锁用来处理这个场景。如果在结构有一个用rwlock_t定义的数据，则在读取数据之前使用read_lock和read_unlock标记，写的时候就用write_lock和write_unlock来标记。

## 进程间通信

下面看一下进程之间是如何保证通信以及同步的（IPC机制）。那么在内核中使用了如下三种：信号量、信息队列和共享内存，它们都用来保证可以在进程间可共享的数据。

### 信号量

这个信号量和上面的信号量就不是一个玩意了。在这里面的信号量并不是只有一个可以原子操作的变量，而是包含了一系列的信号量，所以它支持更多的操作。

在2.6.19版本，IPC引入了名空间来处理：

```
struct ipc_ids *ids[3];
```

在名空间中包含了这样一个变量，这个变量一共有三个入口，分别对应了三种IPC机制。信号量对应它的0号入口。一个ipc_ids结构定义成这样：

```
struct ipc_ids {
    int in_use;  // 标识当前这个IPC机制在使用中
    unsigned short seq; // 这个和下面那个参数生成了该IPC的序号
    unsigned short seq_max;
    struct rw_semaphore rw_mutex;  // 用来处理该信号量的信号量，防止竞态产生
    struct idr ipcs_idr;
};
```

最下面的那个ipcs_idr用来将一个ID和相关的一个kern_ipc_perm结构绑定。

```
struct kern_ipc_perm {
    int id; // 在用户层面可以看到的标识
    key_t key;  // 在内核层面用到的标识
    uid_t uid;
    gid_t gid;
    uid_t cuid;
    gid_t cgid;
    mode_t mode; // 存储了访问控制标志
    unsigned long seq; // 对应了该对象的序列号
};
```

那么在进程的PCB中就有一个和信号量有关的域：struct sysv_sem sysvsem。这个结构中包括了一个队列，这个队列是为了可以完成撤销某个信号量措施的，一旦某个进程在使用了某个信号量后意外退出了，那么就需要使用这个里面数据恢复。

在内核中还有另外两个结构和信号量有关：

下面这个结构是针对那些想要使用这个信号量的进程，但是当时拿不到只能阻塞在这个队列中。

```
struct sem_queue {
    struct sem_queue *next; // 指向队列下一项的指针
    struct sem_queue **prev; // 指向队列前一项的指针
    struct task_struct *sleeper; // 睡眠的进程
    struct sem_undo *undo; // undo结构
    int pid; // 进程标识
    int status;
    struct sem_array *sma; // 存放对于这个操作来说的信号量
    int id; // 信号量的标识
    struct sembuf *sops; // 存放信号量的操作
    int nsops;  // 操作的数量
    int alter;
}
```

在这个结构中也出现了另外一个结构，sem_array，这个结构用来管理此时的信号量的状态：

```
struct sem_array {
    struct kern_ipc_perm sem_perm; // 就是在上面提到的那个kern_ipc_perm
    time_t sem_otime;
    time_t sem_ctime;
    struct sem *sem_base;  // 指向该数组中的信号量
    struct sem_queue *sem_pending; // 等待信号量的进程
    struct sem_queue **sem_pending_last; // 最后一个等待信号量的进程
    struct sem_undo *undo;
    unsigned long sem_nsems;  // 信号量的数目
}
```

这些数据结构彼此是怎么联系起来的哦？最开始一定是从名空间的那个ipc_ids结构开始。通过这个结构的最后一个ipcs_idr信号量的id和kern_ipc_perm联系起来，通过这个值直接遍历找到对应的sem_array项。而这个array中的sem_base代表了这个信号量中包含是的信号量实例的值，而sem_pending存放了阻塞在这个信号量上的进程。

#### 调用实现

在系统中有一个系统调用叫做ipc，这个调用可以完成信号量所有的操作。当然其实在系统中不只有信号量使用这个调用，其他的两个也是使用这个调用实现它的功能。这个调用的第一个参数代表了它需要做的事，比如SEMOP和SEMTIMEDOP代表增加和减少信号量的值。

### 消息队列

进程间可以通过消息的传递来进行通信，那么生成消息的人就叫做发送者，它需要将消息写入一个队列，那么另一个进程从中取走消息就是接收者。所谓的消息就是包括了消息体和一个正整数来表示不同的消息种类，具有相同的标号的消息会以先进先出的顺序排列在队列中。我们看一下消息队列的结构：

```
struct msg_queue {
    struct kern_ipc_perm q_perm;
    time_t q_stime;
    time_t q_rtime;
    time_t q_ctime;
    unsigned long q_cbytes; // 现在队列中包含的字节数
    unsigned long q_qnum; // 队列中的消息数
    unsigned long q_qbytes; // 队列中最大的字节数
    pid_t q_lspid; // 上一个发送者的pid
    pid_t q_lrpid; // 上一个接收者的pid
    
    struct list_head q_messages;
    struct list_head q_receivers;
    struct list_head q_senders;
}
```

q_messages真的消息体，他被封装在msg_msg结构中：

```
struct msg_msg {
    struct list_head m_list;
    long m_type; // 消息的类型
    int m_ts;
    struct msg_msgseg *next // 如果消息长到一个页面装不下，就用这个指针连起来
}
```

### 共享内存

这里简单的提一下具体在内核中共享内存是个什么。在内核中有这样一个shmid_kernel结构，这个结构中存在一个假的文件链接shm_file来创造一个共享内存对象。内核使用这个smh_file中的f_mapping指向一个address space对象创建一个匿名映射。这样刷新页表之后，每一个进程都可以通过该页表项来访问这片共享区域，

## 其他的IPC机制

### 信号

如果你看老的linux的实现，信号是老版的里面常用的通信机制。使用信号时，进程必须要安装处理信号的句柄，这样当信号被传送到该进程时就会触发，当没有特别安装信号句柄时，就使用默认的句柄。当然一个进程可以屏蔽一些信号，这可以借助信号掩码来实现。被阻塞的信号会被挂在阻塞的队列中，如果同一个信号被阻塞多次，那么只会有一个会被加入到列表中。

注册一个信号要借助sigaction结构：

```
struct sigaction {
	__sighandler_t sa_handler;  // 信号处理句柄
	unsigned long sa_flags;
	
	sigset_t sa_mask;
}
```

那么就是用这个结构，用户就可以将针对某个信号的自定义的信号处理句柄替换上去。由于这个特性，**所以注意虽然信号的处理是在内核中，但是安装的信号句柄会在用户空间中运行。**进程中专门有一个sighand_struct结构存放所有安装了的信号句柄。同时一个进程中还会有一个sigpending队列用来存放等待被处理的信号。而其中每一个信号实例就是一个sigqueue，它包含了详细的信号信息。

#### 发送一个信号

这里以sys_tkill为例来看怎么发送信号，它通过find_task_by_vpid找到目标进程的pcb，此时内核需要检查是否这个进程允许发送信号。接下去就是判断，如果这个信号是被阻塞的，就没必要发送；否则生成一个sigqueue实例挂到它的sigpending队列上，随后想办法唤醒目标进程。

#### 处理一个信号

处理信号并不能通过系统调用触发，而是当内核从内核态转换到用户态是自动触发，它是通过末尾处的do_signal调用触发的，它需要从等待队列中取出一个信号，然后将这个信号的处理句柄插入到用户堆栈中，然后回到用户堆栈去执行处理句柄，在处理完后通过sigreturn返回内核看有无其他信号需要处理，如果没有然后需要处理堆栈的内容，回到用户程序运行时的状态继续执行。

### 管道

这也是进程之间的通信方法，管道是使用了虚拟文件系统中的对象来进行数据的传送，一般而言管道就是一个进程将数据塞入一根管道中，随后另一个进程从管道中取走。如果使用管道，那么就需要用pipe系统调用，返回两个文件描述符代表读终端和写终端。管道一直存在在进程空间中，并且如果使用fork或者clone后，管道依然存在。

### 套接字

这个结构是用于网络上的传输，同样接住了虚拟文件系统。套接字同样返回一个文件描述符并且可以和普通文件一样操作它。有关它的实现等到网络子系统中再详细描述。