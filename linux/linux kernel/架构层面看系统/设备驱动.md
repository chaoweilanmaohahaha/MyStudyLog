# 设备驱动

设备驱动是操作系统的一个重要组成部分，它决定了计算机能够连接多少的外部设备

## IO架构

我们需要知道的是对于IO来说，内核一直需要解决三个问题：

* 硬件必须使用一些特有的手段来处理编址问题
* 内核要提供给用户和设备进行交互的手段
* 用户空间必须要知道设备在内核中是可获得的

硬件设备可以以多种方式连接到电脑上，或者说是在主板上的插槽中，要么使用外部连接手段。使用设备扩展也是一种不错的手段。在现在的计算机中所有的外部设备都不是直接和CPU相连，它们是通过总线连接在一起的。那么对于总线来说，也有许多的方法实现总线，其中包括又名的PCI总线（一般在主板中）、ISA和USB等等。无论怎么说，现在的PC都是用多个总线组合在一起，例如现在的PC使用两个PCI总线，它们通过一个bridge连接在一起。

### 和外部设备的交互

一个外部设备可以使用特定的IO端口来进行通信，这种情况下内核会将数据发送给IO控制器，那么特定的设备由端口号标识，那么有一个单独的虚拟地址空间会用来管理IO地址。内核保证不会有两个不同的设备共用一个端口。如果使用这种方法，那么每种处理器访问端口用的指令和方法可能就不同了。

当然设计者也可以将设备的编址和RAM的编址设置成一样，那么处理器需要给出一个内存映射给外部设备，例如PCI经常使用这种方法，那么如果使用这种方法访问的方式就和普通的内存是一样的了。

那么什么时候系统知道一个设备已经准备好了呢？轮询和中断，这里就不展开了。

## 访问设备

**设备文件**用来进入外部扩展设备。这些所谓的文件并不是存在硬盘上的实际文件，就是一个和设备驱动组成的链接。但是从用户的角度来看，这些设备文件和普通文件没什么两样。

那么在系统里面怎么识别它们呢？如果我们使用ls -al,我们就可以清除的发现，如果在列举出来的文件中第一个字母是b或者c，则它们代表了块文件和字符文件，并且其中还给出了设备的主设备号和次设备号。那么内核就是使用主设备号和从设备号来识别设备的。主设备号是用来处理设备驱动的，次设备号用来标识各个使用这个驱动的设备。

这个文件是怎么产生的呢？一般而言设备文件都处于/dev下，那么内核中存在了一个udevd后台进程专门处理动态设备文件的创建。当内核探测到了一个设备，那么一个kobject（内核中驱动的父类）结构就会被创建然后返还给用户空间，当然udevd这个进程还有许多其他的作用，这里就不列举了。

但是比如光有输入和输出操作并不能完全操控好设备，比如如果我要对某个设备进行设置怎么办？那么内核给出的方法就是使用IOCTL方法来对设备进行设置。

这里要最后提到一点就是，并不是所有的都是通过文件的形式来表现，比如网卡。

### 设备号的表示

在老版的内核中实现设备号通常使用8bit表示主设备号，8bit表示次设备号。但是对于大型的系统，这个数据就已经不够了，因此对此进行了扩展——12bit表示主设备号，20bit表示次设备号。那么问题来了，这样就会带来兼容的问题。

那么解决的方法是什么呢？新版内核中如果对外使用dev_t类型，则前8bit用来表示第一部分的次设备号，接下去12bit用来表示主设备号，而最后的12bit用来处理次设备号的剩余部分，在内部依旧保持着0-20是次设备号，后面跟着的是主设备号。这样做就兼容了老的表示方法，当然在内核中也给出了转换的函数。

### 设备的注册

内核必须知道系统中能够使用的具体是哪些设备，这需要一个类似于数据库的结构存储设备信息，另外也要保证提供一个接口来给数据库添加新的设备。

内核中存储块设备和字符设备的数据结构是一样的。只不过最终管理的数据结构不同，一个是cdev，一个是genhd。那么我们主要来看内核是如何去检索这两个结构的。

首先在内核中存在两个全局的结构bdev_map和cdev_map，这两个结构都是使用主设备号进行hash后的一个hash表。它们都是继承了父结构kobj_map

```
struct kobj_map {
	struct probe {
        struct probe *next;  // 所有接在一个链表上的设备
        dev_t dev; // 设备号，包括了主设备号和次设备号
        unsigned long range; // 次设备号的范围
        struct module *owner; // 驱动提供的模块
        kobj_probe_t *get; // 是一个返回这个设备结构的句柄
        
        void *data; // 指向特定设备的数据结构
	} *probes[255];
	struct mutex *lock;
}
```

对于字符设备而言，它有一个单独的数据结构用来管理设备号。这里不在展开。

那么怎么注册一个设备呢，这里就先简单的来看一下：

* 注册一个字符设备，那么首先就要注册或者分配一批设备号，使用alloc_chrdev_region，那么如果申请到了，就可以获得最小的次设备号和设备号范围。那么当设备号申请到了，就需要把设备激活插入到数据库中。这就需要初始化这个cdev结构（cdev_init），然后调用cdev_add插入数据库。
* 块设备的话只需要调用add_disk方法，提供块设备的属性，一个genhd实例就被插入到了数据库中。

## 与文件系统挂钩

之前提到设备文件只要挂到了用户空间下，那就和普通文件没啥两样了，一样它也受到文件的基本操作的控制。那么文件都是通过i结点来管理的，但是可以看到的在有关设备文件的i节点中专门有管理设备的一些字段：

```
struct inode {
    dev_t i_rdev;  // 存储了主设备号和次设备号
    umode_t i_mode; // 存储了设备类型，是块设备还是字符
    struct file_operations *i_fops; // 存放了文件操作，但是同样适合设备文件
    union {
        struct block_device *i_bdev;
        struct cdev *i_cdev;
    }
}
```

当设备文件被打开时，需要对文件操作初始化，那么只需要给当前的i节点附上不同的操作结构地址就可以：

```
inode->i_fop = &def_chr_fops;
```

字符设备十分特殊，因为每一个字符设备都十分不同，因此并不能由系统统一给出一套字符操作，每一个字符设备都会有自己单独的一套操作。但是块设备的操作相对统一，所以只需要使用一套操作就可以了，这个可以由内核给出。

## 字符设备的操作

我们先来看一下字符设备的实例：

```
struct cdev {
	struct kobject kobj;
	struct module *owner; // 如果有驱动，那么指向该驱动使用的模块
	const struct file_operations *ops; // 这个包含了一系列的文件操作和硬件进行通信
	struct list_head list;
	dev_t dev;
	unsigned int count;
}
```

那么当我需要打开一个字符设备文件时，我需要从字符设备的数据库中找到这个设备的cdev实例，那么这样内核就能操作字符设备的文件操作了。但是设想，如果一个主设备号为n，下面有不同个m个次设备号的设备，那么每一个设备都需要提供一个文件操作。那么此时open操作就会指向memory_open，这个操作会给不同的设备分配不同的操作。所以字符设备的操作句柄在打开之后首先按照主设备号装载一次，再按照次设备号装在一次。

具体的读写操作就由不同的设备来实现了。

## 块设备的操作

对于块设备而言，数据总是以一个固定块大小传输的，就算不满一块也读一块，并且块设备读的过程会进行缓存。对于块设备而言有两个简单的属性，逻辑块和扇区，扇区是一个硬件设备指定的最小存储数据的单位，而逻辑块则包含了一系列的扇区。通常情况下，一个扇区有512个字节。在读写时很多块设备会采取预读取的手段，将数据做一步缓存。

### 块设备的表示

内核中使用一种叫做请求队列来管理。内核中使用bdget函数根据块设备设备号获取block_device实例，如果找不到，则需要给设备新开辟一个i节点。对于每一个块设备而言，它都有一个请求队列，所有的读请求和写请求都存在在这个队列中。并且内核中有IO scheduler来重新排列请求。而内核中存在一个gendisk存储了分区情况并且存在低级的读写操作。

```
struct block_device {
    dev_t bd_dev;
    struct inode *bd_inode;  // 指回代表块设备的inode
    int bd_openers;
    
    struct list_head bd_inodes; // 存放所有这个设备的设备文件
    void *bd_holders;
    
    struct block_device *bd_containers;
    unsigned  bd_block_size;
    struct hd_struct *bd_part; // 存放块设备的分区情况
    
    unsigned bd_part_count;
    int bd_invalidated;
    struct gendisk *bd_disk; // 另外一个层面看待块设备的发呢去
    struct list_head bd_list;  // 所有块设备都挂在一个all_bdevs的结构上
}
```

block_device是从驱动层面能看到的块设备实例，而gendisk是一个抽象结构它和真正的内核中的硬盘结构挂钩，里面就包含了整个块设备上的分区信息。

```
struct gendisk {
    int major;
    int first_minor; 
    int minors; // 决定了有多少个分区
    
    char disk_name[32];
    struct hd_struct **part;  // 分区数组，每个元素指向一个分区
    int part_uevent_suppress; // 热插拔
    struct block_device_operations *fops; // 这是代表了底层读写的操作句柄
    struct request_queue *queue; // 请求队列
    void *private_data;
    sector_t capacity;
    int flags;
    struct device *driverfs_dev;
    struct kobject kobj;
}
```

每一个真正的分区实例如下：

```
struct hd_struct {
	sector_t start_sect; // 块设备其实扇区号
	sector_t nr_sects; // 包含的扇区数
	struct kobject kobj;
}
```

那么内核中在注册设备的时候会使用alloc_disk来分配一个gendisk结构，而只有在内核真正发现分区状况时才会建立分区信息。对于每一个打开的分区都会有一个block_device，真正在上层所有的分区情况通过里面的bd_container链接。而所有的block_device又连向一个gendisk，里面存放着一个个分区实例。而系统中还存在一个kset连接着所有的gendisk。

块设备的具体的操作并不需要多谈，就只要提一手revalidate_disk，这是保证老设备被移除后新设备插上需要重新校验一下设备。

下面来看请求队列，所有块设备的读写请求都存在在这个队列上。由于队列结构比较复杂，就不一一写出来了。在每一个驱动中都必须实现自己的一套request_fn函数，这个可以让请求队列的操作和低级的读写程序挂上钩，而这个函数就是向队列中添加一个新的请求。

### 添加磁盘和分区

我们下面看一下具体的add_partition和add_disk函数的实现。对于添加一个分区，我们只需要知道足够的分区信息，然后新开辟一个hd_struct结构，然后需要使用kobj去将分区挂到设备子系统上，最后在gendisk的part分区中装载这个分区就可以了。

添加一个磁盘的方法如下，调用blk_register_region可以确保我申请的这片设备号没有被分配，随后内核创建一个block_device实例。在做完这些之后就要获得磁盘的分区情况，使用rescan_partitions函数，它就可以识别块设备的分区情况，如果识别到了一个分区，就是用上面的add_partition增加。

### 打开块设备文件

这个是借助文件系统中的文件句柄中blkdev_open操作实现的。其中使用bd_aquire获取对应的block_device实例，随后获取其中的gendisk结构。如果之前已经被打开过，则直接使用gendisk中的open函数打开就可以了。如果没打开过，需要考虑因为是第一次打开，需要使用bd_container链接。

### 请求

```
struct request {
    struct list_head queuelist; // 未做完的请求
    struct list_head donelist; // 排列做完的请求
    
    struct request_queue *q; // 指回队列
    unsigned int cmd_flags;
    enum rq_cmd_type_bits cmd_type;
    
    sector_t sector; // 起始扇区
    sector_t hard_sector; // 关联一个实际的硬件设备
    unsigned long nr_sectors; // 还有多少扇区还没传送
    unsigned long hard_nr_sectors;
    unsigned int current_nr_sectors; // 总共需要多少扇区
    
    struct bio *bio; // 这个是真正代表了需要传输的数据，这里相当于还没处理的IO
    struct bio *biotail;
    
    void *elevator_private;
    
    struct gendisk *rq_disk;
    unsigned long start_time;
    
    unsigned short nr_phys_segments;
    unsigned short nr_hw_segments;
    
    unsigned int cmd_len;
}
```

那么一个BIO结构和一个与物理页面直接挂钩的向量有关：

```
struct bio {
    sector_t bi_sector;  // 需要传送的扇区
    struct bio *bi_next; // 挂着几个BIO实例
    struct block_device *bi_bdev; // 指向对应block_device
    
    unsigned short bi_vcnt; // IO向量长度
    unsigned short bi_idx; // 当前正在处理的向量入口
    
    unsigned short bi_phys_segments;
    unsigned short bi_hw_segments;
    
    unsigned int bi_size; // 传送字节数
    struct bio_vec *bi_io_vec; // 指向一个IO向量，里面包含了物理页面
    bio_end_io_t *bi_end_io;
}
```

那么如果我们需要进行数据的传输就需要向某个块设备来提交请求，然后由内核处理这些请求。我们提交一个请求具体就是要创建一个bio实例，然后嵌入这个请求结构中，随后将这个请求插入队列。

bio的创建主要就是给出物理页面并传输数据，一旦bio被创建，那么使用make_request_fn就会生成一个request，而使用request_fn将这个request插入队列。当然在添加bio的过程中有很多的细节，暂时就先跳过了。那么有的时候为了保证性能的优化，系统会让很多请求合并成一个，那么此时就需要收集所有的请求然后进行合并。内核中就会使用队列阻塞机制去防止立刻执行请求。

那么执行请求的时候，只需要根据请求request指定的命令的类型，执行对应的硬件指定的操作就可以了。

### IO调度

传统的，系统中通过一个叫做电梯的来调度IO，这个所谓的调度器不仅可以进行IO的调度和重排序，同时还可以管理整个队列结构。这个结构应该出现在请求队列中。一般我们选择的调度方法是deadline方法，就是尝试让磁盘寻道数大道最少，保证请求在一个确定的时间内执行。

## 预留资源

因为考虑到一个设备需要占用部分端口或者内存空间，所以从一开始就需要给一些设备预留出一些资源。内核中使用了一种数据结构来存放资源：

```
struct resource {
    resource_size_t start; 
    resource_size_t end; // 标识了一个资源区域
    const char *name;
    unsigned long flags;
    struct resource *parent, *sibling, *child;
}
```

可以看到这个结构应当就像一个树结构一样，通过最后的三个指针进行连接，有点像进程的连接哦。这三根指针的连接规则为：

* 每一个孩子都只有一个父亲，而且只要所有的兄弟节点使用一根指针指一下就可以了
* 一个父亲可以有多个孩子
* 所有有着相同的父亲的孩子都是兄弟节点

那么树的每个节点就相当于是一个区间吧，然后作为设备就可以预留资源的某个区间。

### 申请与释放

当一个设备需要申请某片资源的时候，内核就要想办法分配，并且如果这个资源已经被分配出去了，那么这片资源就不能被重复分配。

在内核中使用request_resource函数来请求资源，它扫描了已经存在的资源，然后根据上述链接的规则将新的资源分配上去，要不然就检测处该资源的申请是否有冲突。那么释放资源就是用release_resource函数，根据给出的资源实例去释放相应的资源。

### IO内存

IO内存资源不仅仅包含了那些需要和扩展设备相互交互的那些内存区域，也包含了常规的RAM和ROM空间，这些所有的IO内存地址信息都被保存在一个全局的资源树变量iomem_resource上了。

### IO端口

和IO内存类似，IO端口使用ioport_resource这个资源树来存储端口地址的分配情况。

## 总线系统

真正的外部设备是被设备驱动直接处理的，那么内核需要保证设备如何连到系统上。总线驱动在硬件层面上来说实现是多种多样的，但是这并不意味着内核管理总线的方法不存在共同性，内核使用真实的驱动模型来管理所有的系统总线。

### 真实的驱动模型

虽然总线系统在具体实现上多种多样，但是在内核中的数据结构却是十分类似的，所以在2.6版本的内核之后，真实驱动模型就被投入使用。

```
struct device {
    struct klist klist_children; // 这个是连接了所有低一级设备
    struct klist_node knode_parent;
    struct klist_node knode_driver; // 这个节点会存在与所有使用这个驱动管理的设备中
    struct klist_node knode_bus; 
    struct device *parent; //这个指向了父节点 
    
    struct kobject kobj;
    char bus_id[BUS_ID_SIZE]; // 用来唯一指定设备在总线上的位置
    
    struct bus_type *bus; // 这个是用来指向总线数据结构的，这个设备就属于这个总线
    struct device_driver *driver; // 指向了控制这个设备的驱动程序
    
    void *driver_data;
    void *platform_data;
    
    void (*release)(struct device *dev);
}
```

那么内核中表示设备驱动的数据结构如下：

```
struct device_driver {
    const char *name;
    struct bus_type *bus; // 这个指向了总线数据结构，里面包含了有关总线的一些操作
    struct kobject kobj;
    struct klist klist_devices; // 这个表示所有这个驱动程序所管理的设备
    struct klist_node knode_bus; // 这个用来将所有的设备连接在一个总线上
    
    int (*probe) (struct device *dev); // 这是一个用来检测是否一个设备能够被这个驱动程序所处理
    ...
}
```

当然，内核中也给出了总线数据结构

```
struct bus_type {
    const char  *name;
    
    struct kset subsys;
    struct kset drivers; // 这里包括了所有的驱动 
    struct kset devices; // 这里包括了所有设备
    struct klist klist_devices; //
    struct klist klist_drivers; // 上面这两个数据结构可以帮助你遍历到所有的驱动和设备资源
    
    int (*match)(); // 这个函数是为了给一个设备找到一个合适的驱动程序
    int (*uevent)();
    int (*probe)(); // 这个设备可以探测是否某个设备在系统中
    int (*remove)(); // 可以用来从系统中移除一个设备
    ...
}
```

#### 注册过程

当设备和驱动插入之前，一个总线是必然要有的，那么我们就需要使用bus_register函数给系统加一根总线，这一步先要将自己加入到subsys的kset中，然后为所有它的设备和驱动设置一下。

那么当我们注册一个设备时，需要给设备进行初始化，然后调用device_add函数将设备添加上去。添加需要处理设备之间的继承关系。

最后注册驱动，使用bus_add_driver将驱动添加到总线上

### PCI总线

每一个连接在PCI总线上的可以由三个元素标识：

* bus number：用来标识设备在哪一根总线上
* device number：用来标识在一根总线上的设备
* function number：如果设备还有扩展，就用这个标识

起始对于PCI设备而言，每一个都应该有一个256字节长的配置信息，在这里就不具体说明了，直接跳到内核中对PCI总线的实现。

PCI设备在不同的系统中初始化的方法是不同的，对于IA-32来讲所有有关PCI的资源都是在启动时通过BIOS的帮助来进行初始化的。那么内核中自然给出了一些数据结构来管理PCI。包括特别的pci_bus,pci_dev和pci_driver。当然那么在系统中使用了pci_root_buses列举了所有的pci总线，pci_devices列举了所有的pci设备。

```
struct pci_bus {
    struct list_head node;  // 这就是pci_root_buses中的一个元素
    struct pci_bus *parent; // parent指向了高一级的总线结构
    struct list_head children; // 指向低一级的总线
    struct list_head devices;  // 所有在这跟总线上管理的设备
    struct pci_dev *self; 
    struct resource *resource[PCI_BUS_NUM_RESOURCE]; // 这个就是之前提到的预留的资源，pci默认预留虚拟地址空间来进行内存的映射
    
    struct pci_ops *ops; // 所有有关pci总线的操作
    void *sysdata;
    struct proc_dir_entry *procdir;
    
    char name[48];
}
```

那么pci_device呢？

```
struct pci_dev {
    struct list_head global_list; // 这是在全局变量pci_devices节点
    struct list_head bus_list; // 这个是出现在这个设备存在的那个总线的链表上
    struct pci_bus *bus; // 属于的那个总线实例
    struct pci_bus *subordinate; //如果这个设备代表了PCI之间的桥
    
    /*
    	这个区域内保存的都是所有pci设备配置文件中的字段
    */
    
    struct pci_driver *driver; //指向控制这个设备的驱动
    struct device dev; // 这是连向一个内核中真实的设备模型的指针
    
    struct resource resource[DEVICE_COUNT_RESOURCE]； // 这个设备占用的资源
}
```

那么pci_driver呢？

```
struct pci_driver {
    char *name;
    const struct pci_device_id *id_table;
    // 驱动最重要的就是要处理设备的删除安装和检测
    int (probe*)(); // 用来检测是否这个设备适配这个驱动
    int (remove*)(); // 用来删除一个设备
    struct device_driver driver; // 这个相当于指向了一个内核中真实的驱动实例
}
```

PCI驱动可以使用pci_register_driver来进行注册，这个函数会让pci驱动和内核中的驱动进行一个挂钩，当然更重要的是，这个函数会建立一个所有设备的列表，这个列表包括了这个驱动所适配的设备。那么上面结构中的*id_table就是用来做这个事情的。

### USB总线

USB最有名的要数它的设计真的很好的实现了热插拔和安装的透明性。USB有什么特殊性呢？其实就在于它的排列设备的拓扑结构，它从一个根控制器出发，设备通过一个个hub组成了一个类似于树一样的结构。只要是所有支持了PCI卡的架构都可以很好地支持USB。

在USB中，设备可以是任何的一个东西，每一个设备可能会使用两套不同的设置，并且可能包含多个接口，对应的接口可能又有不同的连接点。USB中也定义了四种传输方法：

* 控制传输：传输控制信息来对设备进行配置。
* 块传输：可以占用完整的总线带宽传输数据包。
* 中断传输：可以在一个时间段内重复传输
* 指定带宽传输

USB子系统一共实现了两个层面：一个是给适配器的驱动用来连接总线系统（比如PCI）和USB设备链的，还有就是单独处理某个设备的驱动。USB子系统需要完成四个工作：注册以及管理设备的驱动，找到一个合适的驱动来给设备进行初始化和配置，在内核空间中表示一个设备，和一个设备进行通信。

在内核中使用usb_driver结构来存储USB系统和总线之间的驱动：

```
struct usb_driver {
    const char *name;
    int (*probe) ();
    void (*disconnect) ();
    const struct usb_devie_id *id_table;
    struct usbdrv_wrap drvwrap;
}
```

其中drvwrap建立usb_driver和真正的设备驱动之间的联系，因为一个device_driver对象嵌在其中：

```
struct usbdrv_wrap {
    struct device_driver driver;
    int for_devices;
}
```

内核会扫描id_table,这个结构包括了所有这个驱动支持的设备，这个id_table中就包含了所有适配的设备。那么如果找到了就对设备进行初始化，否则呢就去另一个驱动上找。

我们之前讲到，USB设备的连接就像一棵树一样，那么自然在内核中就有结构需要对这个结构进行支持。

```
struct usb_device {
    int devnum;
    char devpath[16]; // 这个变量描述了该设备在树中的路径。
    enum usb_device_state state;
    enum usb_device_speed speed;
    
    struct usb_device *parent; // 就指向了它指向的那个hub
    struct usb_bus *bus; // 指向连接在哪根总线上
    
    struct device dev; // 和真实的内核中的设备结构来呢西
    
    /*
    	usb 配置信息
    */
    
    int maxchild; // 如果以下信息有设置，说明该节点是一个hub
    struct usb_device *children[USB_MAXCHILDREN]; //包含了hub连接的那些usb设备
}
```

```
struct usb_bus {
    struct device *controller; // 这个指向在内核中硬件实现的总线实例
    int busnum;
    char *bus_name;
    
    struct usb_devmap devmap; // 跟踪usb分配情况的一个位图
    struct usb_device *root_hub; // 这个指向这个usb子系统中树结构的根设备节点
    struct list_head bus_list; //这个是在全局列举所有总线的列表中的元素
    
    struct dentry *usbfs_dentry; // 文件系统入口
}
```

最后在这里提一句，和这个控制器进行通信，usb设备采用的是usb请求块，通过这个请求块usb设备之间可以互相传递数据。

**对于驱动的具体信息还是到设备驱动里面再令行讨论吧**

