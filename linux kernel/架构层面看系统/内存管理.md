# 内存管理

内存管理是内核中最重要的部分之一，那么以下的内存管理需要处理什么问题呢？

1. 管理物理页
2. 伙伴系统分配内存空间
3. 分配小的内存空间
4. vmalloc机制分配不连续内存空间
5. 用户进程的内存空间

在前面其实已经提到了虚拟地址空间的概念了，对于一个进程来说每一个进程都会有它的虚拟内存空间，基本以3：1分配用户地址空间和内核地址空间。同时我们还会知道，物理地址是通过映射的方法和内核地址空间产生关联。**有个比较重要的是，虚拟地址空间理论上要小于CPU最大的理论地址空间。**

对于管理物理地址空间来说，一般有两种方法：统一内存访问（UMA）和非统一内存访问（NUMA）。那么就先从这个开始说起吧。

### UMA and NUMA

为了不失一般性，在理解所谓物理内存的结构时，先从非统一内存访问所要使用的数据结构开始理解。我们可以把一个RAM内存划分为多个节点（node），这个所谓的节点是和处理器挂钩的（由数据结构pg_data_t表示）。在每一个节点中间又需要划分多个区域（zone），一个节点是由3个zone组成的，一个zone代表的是高内存空间，一个zone代表DMA操作空间，还有剩下一个是普通使用的内存空间。每一个区域又由一个数组构成，数组元素代表了真正的物理页，就是所谓的页框。这个多个节点就是给非同一内存访问使用的，每个处理器相当于占用了一个node，而UMA模式下就只会使用一个node。

那么来熟悉一下pg_data_t的一个具体的结构。

```
typedef struct pglist_data { 
	struct zone node_zones[MAX_NR_ZONES];  //zones
	struct zonelist node_zonelists[MAX_ZONELISTS];  //备用的节点，用来处理装不下的情况 
	int nr_zones;  //zone的数目
	struct page *node_mem_map;  //所有节点中所对应的所有物理页
	struct bootmem_data *bdata; //用于启动系统的内存
	unsigned long node_start_pfn;  //UMA下始终为0
	unsigned long node_present_pages; /* total number of physical pages */ 
	unsigned long node_spanned_pages; /* total size of physical page range, including holes */ 
	int node_id;   //node标识符
	struct pglist_data *pgdat_next; //连接下一个node的指针
	wait_queue_head_t kswapd_wait; 
	struct task_struct *kswapd; 
	int kswapd_max_order; 
} pg_data_t;
```

接着是zone的结构：

```
struct zone { 
	/* Fields commonly accessed by the page allocator */ 
	unsigned long pages_min, pages_low, pages_high;
	//这三个标记用作页兑换来使用，如果当前有大于pages_high的页，那么说明该zone是理想的；如果当前的空余页数已经小于等于pages_low，那么就要考虑和磁盘开始兑换;如果低于了pages_low,那就说明这个zone上已经很缺空闲页了.
	unsigned long lowmem_reserve[MAX_NR_ZONES]; //保留页,用来给那些比较紧急的分配事务
	struct per_cpu_pageset pageset[NR_CPUS];  //所谓冷热页序列,后面解释什么是冷热页
	/* * free areas of different sizes */ 
	spinlock_t lock;   // 自旋锁，防止多个处理器读
	struct free_area free_area[MAX_ORDER]; //用来实现伙伴系统
	ZONE_PADDING(_pad1_)
	/* Fields commonly accessed by the page reclaim scanner */ 
	spinlock_t lru_lock;   //同样防止多个处理器进入
	struct list_head active_list;  //标识了所有活跃的页,就是指它经常被访问
	struct list_head inactive_list;  //标识了所有的不活跃的页,就是指它不经常被访问
	unsigned long nr_scan_active; //代表回收内存时扫描的活跃页
	unsigned long nr_scan_inactive;  //和上面的一样,不活跃页数
	unsigned long pages_scanned;  //上一次页面被换出后扫描失败的页面
	/* since last reclaim */
	unsigned long flags; /* zone flags, see below */  //代表这个zone的类型
	/* Zone statistics */ 
	atomic_long_t vm_stat[NR_VM_ZONE_STAT_ITEMS];  //存放大量关于该zone的静态信息
	int prev_priority; //
	ZONE_PADDING(_pad2_) 
	/* Rarely used or read-mostly fields */
	wait_queue_head_t * wait_table;   //处理器等待该页面的等待队列
	unsigned long wait_table_hash_nr_entries; 
	unsigned long wait_table_bits;
	/* Discontig memory support fields. */ 
	struct pglist_data *zone_pgdat;   //这个使得node和zone产生了关联
	unsigned long zone_start_pfn; //指示了这个zone的第一个页框的系数
	unsigned long spanned_pages; 
	/* total size, including holes */ 
	unsigned long present_pages; 
	/* amount of memory (excluding holes) */
	/* * rarely used fields: */ 
	char *name; 
} ____cacheline_maxaligned_in_smp;
```

**冷热页队列**

热页指的是一个页面在CPU的cache中,所以它的数据可以更快地被获取;那么相反一个冷页并不在cache中。这个pageset的一项就分为了两个队列，分别为冷队列和热队列。而这个队列中的每一个元素由以下的几个属性标识：

```
struct per_cpu_pages { 
	int count; /* number of pages in the list */ 
	int high; /* high watermark, emptying needed */   //意思是这个队列中的最大值
	int batch; /* chunk size for buddy add/remove */   //一次性加的页数
	struct list_head list; /* the list of pages */  //真正接页面的链表
};
```

**页框**

页框是系统内存中最小的单元。在linux的设计中页框的大小要尽可能的小，但是再小的页面也要被几个应用所使用，因此一个页面可能会被分为多个部分。因此真正在实现的时候使用到了联合体。一个物理页可以被页表映射到多个虚拟地址空间处，这样在这个物理页结构中有一个计数器专门记录页框被映射的次数。如果这一个页框被分为许多小部分供多个应用去使用，那么这个计数就代表使用该页框的应用数。页框的结构如下所述：

```
struct page { 
    unsigned long flags; //这个存放了和架构无关的一些标志，这些所谓的标志有很多都是指该页框现在处于的状态，比如该页是否被修改，是否上锁等等这些状态。
    atomic_t _count;  //这个页框的引用次数，如果引用次数为0则说明这个页框现在并没有被使用
    union { 
    	atomic_t _mapcount; 
    	unsigned int inuse; /* SLUB: Nr of objects */
	}; 
	union { 
		struct { 
			unsigned long private; 
			struct address_space *mapping;  //这个部分是该页框在地址空间的位置
		};
...
	struct kmem_cache *slab;  //slub分配器独有
	struct page *first_page;  //在分配时有这么一种情况，就是可能将多个页框合并分配，那么所有后续页框指向第一页
	}; 
	union {
		pgoff_t index; 	   //和该页框在地址空间的位置有关
		void *freelist;    //slub分配器独有
	}; 
	struct list_head lru;  //用来对不同的页框分类使用
#if defined(WANT_PAGE_VIRTUAL) 
	void *virtual;   //用作高内存区区域的页框
#endif 
};
```

### 页表

页表用来快速地管理大量的地址空间，它是将用户进程的虚拟地址和实际的页框物理地址进行关联。每一个进程都可以拥有自己的页表。2.6内核内存管理分为四级页表，那么虚拟地址就会被划分为五个部分，Offset代表页框中的偏移，PTE代表一级页表中的偏移，PMD代表二级页表中的偏移，PUD代表三级页表中的偏移，PGD代表四级页表中的偏移。最高级页表的基址被存在一个特定的地方。最后的入口并不只是代表了一根指向实际地址的指针，而是带有了许多额外的信息，使用了一些bit来记录，这些信息通常是和该页有关的控制信息。

### 初始化

对于内存的初始化有着很多层意思，比如在引导阶段需要一些空间来帮助系统完成引导，而这些空间在后面将不会再使用。内存初始化作为系统中最为重要的一个部分，它在一些与系统相关的初始化之后立刻就进行了。也就是说pg_data_t这个结构就在这个时候被初始化了。大部分的系统都只有一个node，那么为了保证系统代码的扩展性，系统使用了contig_page_data来管理了所有的系统内存。

#define NODE_DATA(nid)  (&contig_page_data)

注意这个nid就是专门为了NUMA所准备的，但是你可以看到其实都会被映射到一个实例上，那么对于普通的UMA系统，这个nid参数默认为1。

接下来就是系统在最开始对于内存的初始化操作：

系统会使用setup_arch对一些与架构挂钩的属性进行设置，然后使用setup_per_cpu_areas对每个CPU变量进行初始化。当这两步进行完后，就正式对内存单元进行初始化了。build_all_zonelists构造了node和zone所需要的数据结构。（这里小提一下，对于UMA和NUMA，它们使用的同一套操作函数，内部的实现是通过编译时一些宏定义来区分的。）对于UMA，因为只有一个node，所以这个函数中直接将contig_page_data结构赋给了pg_data_t，而对于NUMA来说就需要多次赋值，构造多个node。然后将pg_data_t作为参数交给build_zonelists在各个zone中建立一个顺序。这是什么意思？比如如果系统想申请一片区域从当前的高内存区域中，如果失败了就会去查看下一个普通的内存区域，如果再失败了就会查看DMA区域，如果再失败了就会去别的node中去查看。这就是一个顺序。所以这个函数会在一个node上的zone中建立一个申请顺序的同时，对于存在多个node的情况也会对查找node的顺序进行一定的限制。这一项填充在了pg_data_t的zonelists结构中。那么真正的初始化操作如下代码：

```
static void __init build_zonelists(pg_data_t *pgdat) { 
	int node, local_node; 
	enum zone_type i,j;
	local_node = pgdat->node_id; 
	for (i = 0; i < MAX_NR_ZONES; i++) { 
		struct zonelist *zonelist;
		zonelist = pgdat->node_zonelists + i;  //每个node的zonelist入口
		j = build_zonelists_node(pgdat, zonelist, 0, j);
	... 
}

```

```
static int __init build_zonelists_node(pg_data_t *pgdat, struct zonelist *zonelist, int nr_zones, enum zone_type zone_type) { 
	struct zone *zone;
	do {
		zone = pgdat->node_zones + zone_type;   //初始化不同种类的zone
		if (populated_zone(zone)) { 
			zonelist->zones[nr_zones++] = zone; //初始化该node中的zonelist
		} 
		zone_type--;
	} while (zone_type >= 0); 
	return nr_zones;  //其实返回的是种类数
}

```

当我们完成了结构的初始化后就要进行所谓的建立顺序的操作了。

```
static void __init build_zonelists(pg_data_t *pgdat) { 
	... 
	for (node = local_node + 1; node < MAX_NUMNODES; node++) { 
		j = build_zonelists_node(NODE_DATA(node), zonelist, j, i); 
	} 
	for (node = 0; node < local_node; node++) { 
		j = build_zonelists_node(NODE_DATA(node), zonelist, j, i); 
	}
	zonelist->zones[j] = NULL;
	}
} 
} //这里的代码就是循环往后进行拼接，举个例子，如果当前正在初始化的node是2号，如果一共有4个node，那么拼接出的就是2->3->0->1，这就是所谓node的顺序

```

#### 与架构有关的初始化

（本篇只关注IA-32和AMD64两种架构。）在真正接触初始化之前，先要了解一些和物理RAM有关的内容。内核真正在物理RAM中是这样分布的：开始的4KB是第一个物理页框，这个通常被BIOS保留。接下去的640KB内容是可用的，但是在内核被被加载后就不会再使用了，因为这片区域之后紧接着就是系统的ROM和显卡。而显卡末尾位置为1MB。那么如果使用这片区域来加载内核则内核的大小一定要小于640KB，IA-32为了解决这个问题就让内核的加载位置放到了1MB后。\_text和\_etext标识了内核代码的开始地址和结束地址。需要的数据部分在\_etext和\_edata中间。而最后到\_end的这篇区域内就包含了其他初始化数据。你可以通过System.map这个文件来查看，也可以通过/proc/iomem来查看。

###### 初始化时的操作

下面主要介绍内核在初始化的时候一些有关内存分配的一系列操作：

machine_specific_memory_setup，这个函数是最先被调用的有关内存分配的函数，这是为了获得建立一个列表哪些内存区域被系统利用而哪些没有。通常这个信息在BIOS中有写，如果没有指定这样的信息内核就会自己建立一个表格。然后内核使用parse_cmdline_early分析命令行的参数，管理员可以用这个功能来覆写一些已经设置好的有关内存分配的参数。接下来进入setup_memory，这个函数对于内存连续和内存不连续的机器实现是不一样的。但是它们都可以使用这个函数来决定物理页数，保留的内存空间以及用于引导的内存空间。随后内核调用paging_init初始化内核页表并且允许分页。最后就是调用zone_size_init函数初始化所谓pgdat_t的实例了。以上的操作是在IA-32架构中出现的，如果是AMD64架构的计算机，则初始化的流程也十分相似。下面着重来看这个paging_init这个过程。

首先要知道的一点，这个page_init的作用之一是初始化只有内核能使用的页表。首先一点我们要回忆以下进程的虚拟地址空间，内核会将这个空间分为3GIB的用户地址空间和1GIB的内核地址空间，用户地址空间是每个进程所独有的，但是内核空间而言当通过系统调用陷入了内核态，此时内核处理时必须在一个很稳定安全的地方，那么就需要让内核完全占用一个地址空间，而这个空间可以直接映射到物理页。

此时来看一下地址空间的划分，我们知道0-3G一定是给用户的，而3G-4G是给内核的。但是思考一下如果将内核空间都映射到了物理页上也只会只用物理页的1G空间，也就是如果物理内存有4G，剩下的3G将永远无法访问。在内核中就使用了高端内存的办法来解决这个问题，高端内存的思想就是借用这一片区域来映射对应的物理内存。其实在真正的机器中是不会映射1G的，只有映射896M，那么还剩128M用来干嘛了？（所以我们回忆在之前讲到物理地址空间分为三种区域，即DMA区域，normal区域和高端区域，像normal区域就是用来和内核逻辑地址进行一一映射用的，而剩下的高端地址就是使用接下来说的vmalloc动态地址映射来进行使用）它们分别使用来进行vmalloc，永久映射和固定映射使用。所谓的高端地址就是从0xF8000000~0xFFFFFFFF。

这时就可以详细说说这个函数试怎么做的了。首先通过pagetable_init函数初始化系统页表。然后将896M的物理地址映射上去。当然完成这一步的同时剩下的128M也初始化完毕了。当这一步完成后，就会初始化cr3寄存器，指向全局页目录。接下来冲刷TLB。最后使用了kmap_init函数初始化一个叫做kmap_pte的变量来指定用来进行将高内存地址映射到内核地址空间的一张页表入口。

下面来看一下AMD64上是怎么操作的。因为64位的虚拟地址，使得它并不需要借助高位地址的来处理映射关系，这比32位虚拟地址的情况略微简单。但是这样反过来想，目前物理地址最大支持48位，这样使用有些虚拟地址无法用来进行映射。内核中解决这个的办法是使用一种符号映射的方法来处理问题的。具体的方法是地址的0-46位用来进行设置，而47-63位则要么全设为1要么全设为0。这样整个虚拟地址空间被划分为了3个部分：高位内核地址，禁止使用空间和低位用户进程空间。

###### 引导过程的内存管理

在引导阶段，内核也需要一些空间让它能够完成引导。在内核中bootmem allocator这个部分就是用来在引导时为内核分配存储空间的。在内核中使用一个bitmap来管理所有物理页的使用情况，那么这个allocator会扫描这个bitmap来搜索出第一个最合适的连续的页面。内核中会使用一个bootmem_data的数据结构，而这个数据结构占用的空间必须在编译时指定。

```
typedef struct bootmem_data { 
	unsigned long node_boot_start;   //系统中的第一页，通常为0
	unsigned long node_low_pfn;    //物理地址空间最后一页，就是zone_normal的位置
 	void *node_bootmem_map;  //bitmap的地址 
	unsigned long last_offset;  //最后一次分配的页偏移
	unsigned long last_pos;   //最后一次分配的页
	unsigned long last_success;  //指定最后一此分配成功的位置，也是下一次分配的开始位置
	struct list_head list;  //
} bootmem_data_t;
```

那么初始化这样的一个结构是一个和架构有关的过程。在IA-32架构上，它会使用setup_memory函数从低地址区域中检测可以用的最大页框数。然后根据这个信息来初始化这个结构。而对于AMD64，bootmem_bootmap_bitmap 计算了bootmem_map需要使用的页数，然后根据这个信息，来初始化bootmen数据。（具体过程后面补充）

