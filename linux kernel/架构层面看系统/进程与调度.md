# 进程与调度

其实对于进程与调度而要最重要的几个问题无非就是进程的隔离以及进程调度问题，而关于进程调度，内核又需要直到当时间片结束之后应该选择谁来参与调度，每一个进程又应当给与多大的时间片运行，调度过程中从A进程到B进程的切换要保存A进程的现场，这些问题都值得考虑，先一步一步来看linux（2.6）中有关进程的知识点：

### 进程优先级

linux系统是一个抢占式的多任务系统。进程的优先级影响到进程被调度时的选择，在内核0.11版本的代码中已经有了进程优先级的概念了，当所有进程时间片都用完后，总需要挑选一个进程参与调度，这就要借助进程优先级。其实对于一个进程而言一般划分为实时进程与非实时进程两种。

* 实时进程：这样的进程需要在一个特定的时间内完成。所以这一类进程有个比较核心的特征就是进程调度时需要带有一个时间帧结构，并且系统要保证进程运行的时间不能超过这个帧长。但是这一类进程在linux中并不是十分支持。
* 软实时进程：这类进程与上面的实时进程比较类似，但是这些进程也需要较快被处理，只不过相对可以被延后一些。
* 普通进程：这时绝大多数进程属于的类型，这类进程没有对于时间特别的限制，但是要注意这类进程也可以再给它们赋予优先级来表示各自的重要程度。

那么系统根据这些优先级，也就是进程的重要程度来分配时间片。你可以想象一下一个简单的模型，所有的进程相当于围成一个圈，有一个监视器在扫描这个圈，如果某一个进程的时间片耗尽就调度下一个进程，然后如果上一个进程还没运行完保存对应的寄存器和页表信息。

### 进程的生命周期

简单的说一个进程并不是时时刻刻都在运行，进程可以处于不同的状态：

* 运行态：进程占用着CPU和相应的资源，正在运行。
* 就绪态：进程能够运行的标志是它已经拿到了所有需要的资源了，只需要获取CPU的调度就可以参与运行。
* 睡眠（阻塞）态：这种状态是不能被调度的，需要一个外部事件的触发来唤醒。

调度程序需要直到所有进程的状态从而进行判断应该调度哪个程序，既然有这么多状态，进程必然是可以从这些状态中切换的。

当一个进程拥有了所有资源而准备运行时，重要它被分配到了CPU时间，它就从就绪态转变为了运行态，而在运行中的进程如果失去了CPU则就又回到了就绪态；如果在运行中的进程因为需要某个事件的发生而无法继续运行下去了，则它必须从运行态进入阻塞态。而如果这个事件发生了，则阻塞态的进程也就具备了被调度的资源，这样该进程被修改为就绪态等待调度。如果进程运行完了，那么它会进入停止态。在这里有一个特殊的进程状态：**僵死态**。这种状态的进程资源已经被系统回收了，但是它仍然存在于进程表中，这种状态只有在一个程序被用户直接杀死时才会出现。

对于一个进程而言，它又有两种运行模式：**用户模式**和**内核模式**。运行在用户模式下的进程只能在自己的内存空间下运行，但是内核模式则拥有所有的权限。如果一个进程需要获取系统数据和系统函数，则必须进入内核模式，一共有两种方法可以做到：**系统调用**和**中断**。系统调用是人为控制的，但是中断不是，中断和正在跑的进程可以说基本没有关系。中断可以改变进程的状态：普通的进程是可以被中断的；在内核模式下处理系统调用是无法被收回CPU的，除非碰到一个中断，中断可以使用户模式和内核模式下的程序终止，它有最高的优先级。

### 进程表示

在内核代码中一个进程的表示是通过一个名叫task_struct的数据结构定义的，这里不能展示它所有的成员因为实在是太多了，先做个小总结在里面都有些什么：

* 进程执行时信息，包括pid，信号，父亲指针和兄弟指针，时钟等
* 虚拟内存信息
* 进程附带的用户和组信息
* 文件信息
* 线程信息
* 信号处理信息

在这里顺便讲一下在上面提到的状态，在这个里面是由一个叫state的参数，它被指派为一系列已经定义好的宏定义：

* TASK_RUNNING:正在运行或者就绪的状态；
* TASK_INTERRUPTIBLE: 一般的阻塞状态；
* TASK_UNINTERRUPTIBLE: 只能被内核唤醒而不能由外部事件唤醒的阻塞状态；
* TASK_STOPPED: 停止状态。

这里再带过一个知识点，linux内核中给每一个进程提供了一个资源限制机制，用rlimit结构表示，这部分信息被存储在proc文件系统中

##### 进程类型

你可以通过如下三种方式来生成新的进程：

**fork**：在父进程的基础上生成子进程，生成的过程是就是将所有父进程的资源统统拷贝一份下来，经过这个系统调用后，就会有两个独立的示例跑在原始的进程上。

**exec**：这个加载一个新的可执行文件来代替一个运行的进程，其实准确地说，exec并不会产生一个新进程，就是加载一个新的程序，具体步骤是先将老进程fork一下，然后执行exec调用。

**clone**：这个调用的操作和fork类似，只不过生成的实例不是一个独立的实例，需要和父进程共享一些资源。因此这个方法一般用来建立线程。

##### 名空间

这个概念比较特别，它的本意是做到空间隔离的效果。一个名空间你可以把它看成是一个单独的linux系统，在系统中有许多全局变量需要被管理，那么这些全局变量可以映射到某个名空间中，而两个名空间之间关于这些变量是隔离的，你无法从一个名空间中去查看另一个名空间中的变量，因此给人的感觉是一个个独立的linux系统，在这个名空间上你也运行着init方法和其他子进程。名空间是由继承性的，如果一个名空间中的某些进程被映射到父名空间上，那么父名空间是可以管理子名空间上的进程状态，但是子名空间无法看到上层。

在linux系统中在task_struct结构中专门有一个值为nsproxy，这是一个名空间数据结构，里面存放着指向不同类型名空间的指针，包括uts_namespace,user_namespace,mnt_namespace，这些指针指向一个个名空间实例。**关于名空间的说法确实还要再看一遍，加深理解**。

##### 进程标识

关于进程的标识，其实在接触操作系统的时候就应该直到，进程使用pid标识的。但是在操作系统的不同层面上来标识进程使用的标识是繁多的并且是不同的。

* 在一个线程组中的进程有标识TGID，有说法认为它就是pid。
* 一个进程可以被划分入一个进程组，也就是在task_struct中有pgrp这个值，而如果不是在进程组中的leader进程，在task_struct中的pgrp都应该等于leader进程的pid号。
* 不同的进程组又被合成一个会话。会话有一个专门的会话ID

这里有一个小trick，那就是对于名空间中的pid名空间是有继承性质的，也就是说父空间可以看到子空间但是子空间无法看到父空间。

下面谈一下linux里对于pid的管理：

先看一下pid名空间的数据结构:

```
struct pid_namespace{
    struct task_struct *child_reaper;   //指向任务的结构，说明该名空间隶属于某个进程
    int level;  //名空间层级
    struct pid_namespace *parent;  //有继承关系的父亲空间，应该指的是根父亲
}
```

```
struct pid {
    atomic_t count;  //计数
    struct hlist_head task[PIDTYPE_MAX]; //根据每一种ID类型，在hash表中的一个链表头
    int level;  //层级
    struct upid numbers[1];  //代表的是每一层级的一个upid实例
}
```

```
struct upid {
    int nr;   //数字表示的ID
    struct pid_namespace *ns;  //指向隶属的名空间
    struct hlist_node pid_chain; //一个hash表
}
```

上面的两个分别为pid和upid的结构，pid就是内核所能理解的pid结构，而upid结构代表在特定的名空间内所能看到的信息。那么一个pid到底有多少信息呢，可以看到一个PID值根据进程中ID类型的不同，可以指派给多个进程，而这些进程会被挂载hlist_head上，这些进程根据类型的不同会挂在不同的位置。比如一个PID的值会被指派给PIDTYPE_PID, PIDTYPE_PGID, PIDTYPE_SID。那么对于一个pid来说它可以通过upid实例去看到名空间内进程的情况。

在task_struct中有这么一个值：

```
struct pid_link pids[PIDTYPE_MAX]
```

```
struct pid_link {
    struct hlist_node node;
    struct pid *pid;
}
```

然后在同一个文件中有这样一个结构

```
static struct hlist_head *pid_hash
```

这边就要理解一下这些数据结构之间到底什么关系了，对于一个进程来说，pids是一个pid hash表。在pid结构中tasks代表的是使用该类型pid的一个表头，而pids就是这个表的真正的结点，也就是tasks表上的结点。

pid_hash这个结构是负责从一个名空间的数值PID找到该pid的实例，因此这个hash是由名空间和pid一起hash得到的。

那么赋予一个进程pid的方法就是：

```
int fastcall attach_pid(struct task_struct *task, enum pid_type type, struct pid *pid) { 	 struct pid_link *link;
	link = &task->pids[type]; 
	link->pid = pid;  //赋予pid
	hlist_add_head_rcu(&link->node, &pid->tasks[type]);  //节点加入pid的task
	return 0;
}

```

##### 进程之间的关系

1. 父子关系：A如果fork出了B， 那么B就是A的子进程，当然这个有继承，比如爷孙进程。
2. 兄弟关系：A同时fork出了很多进程，那么这些进程就是兄弟进程。

所以在task_struct中有专门存放这些值的地方：

```
struct list_head children
struct list_head sibling
```

### 进程管理的系统调用

##### 如何创建一个子进程？--- fork

其实对于系统内核而言，fork的实现有三种，有一种clone的放到下面来说，而其中两种一种是fork，这是一种重量级的函数，它需要完全复制一个父进程，但是在linux中有一种计数叫做COW可以减少工作量。另一种称为vfork，这种方法一般适用于子进程生成后直接执行一个新的程序而使用的，这个后面详细介绍。

对于最基本的fork来说，如果每次在fork的时候先开辟一个新的空间，然后再把父进程的信息全部拷贝到新的空间中，这个操作付出的代价是巨大的。如果每次都这么操作势必开销很大。那么在linux中它是使用了一种copy on write的方法。首先在fork过程中只拷贝了父进程的页表而并没有拷贝地址空间的信息，这样使得子进程和父进程指向了同一片物理地址区域。但是现在这一片地址区域是无法修改的，而是只读的，那么如果子进程中只要读这篇地址区域的信息自然就没有必要进行其他附带操作了；如果子进程要写这片区域，则会报缺页错误，然后这时重新开辟一篇地址区域，再进行copy。

看一下实现的函数：

```
long do_fork(
	unsigned long clone_flags,   // 区分不同的fork操作
	unsigned long stack_start,   // 用户空间堆栈
	struct pt_regs *regs,   // 指向原本存放的寄存器信息
	unsigned long stack_size,  //堆栈长度，一般设置位0
	int __user *parent_tidptr,  //父子进程的tid号
	int __user *child_tidptr
)
asmlinkage int sys_fork(struct pt_regs regs) { 
	return do_fork(SIGCHLD, regs.esp, &regs, 0, NULL, NULL); 
}
```

具体这个fork函数怎么做的呢？首先fork会调用copy_process例程，这个函数会生成一个新进程并且复用父进程的资源。fork的最后会返回新的pid，但是获取这个pid的方法要考虑到是否又生成一个新的名空间。然后新的进程插入到了就绪队列中等待调度。如果这个fork的过程使用了vfork机制，那么父进程最后要执行一个wait_for_completion函数等待子进程退出。在copy_process历程中，首先检查各个标志位的值，然后使用dup_task_struct函数复制一个与父进程相同的进程。注意新进程和旧进程的唯一区别就是内核栈空间是不同的。这个信息存储在一个联合体中：

```
union thread_union { 
	struct thread_info thread_info; 
	unsigned long stack[THREAD_SIZE/sizeof(long)]; 
};
```

thread_info保存了汇编语言可以获取的进程信息。所以在复制时这个stack信息时不会复制的，会重新开辟。

在复制结束后，系统会检查创建新进程后是否超过了特定用户的创建进程数的上限了，那么检查该信息就要用到上面提到的rlim结构了。如果超过了限制就会终止新进程的创建。正常情况下会继续调用sche_fork函数会给新的进程设置一些信息。接着就是复制父进程中的许多资源，但是这里的复制对于其中的指针来说也是直接复制的，因此在最开始新进程和旧进程在一些资源上还是使用的同一个资源。那么这里又要靠flag来区分了，如果flag中代表某一个资源的那一位被置位，则需要重新创建响应的资源。最后就是填充一些子进程所特有的信息了。

##### 如何创建一个线程？ --- clone

clone函数的实现也是借助上面提到的do_fork函数，只不过调用的时候有一些区别。

```
asmlinkage int sys_clone(struct pt_regs regs) { 
	unsigned long clone_flags; 
	unsigned long newsp; 
	int __user *parent_tidptr, *child_tidptr;
	clone_flags = regs.ebx; newsp = regs.ecx; 
	parent_tidptr = (int __user *)regs.edx; 
	child_tidptr = (int __user *)regs.edi; 
	if (!newsp) newsp = regs.esp; 
	return do_fork(clone_flags, newsp, &regs, 0, parent_tidptr, child_tidptr);
}

```

对于线程而言，父进程并不是正在fork的进程。它们的执行被看成是在子进程中又进行的，因此它们的父进程应该时父亲的父亲。其余的一些和进程的fork不同的地方也就是多了几个标志位，其余都是一样的。

##### 内核线程是什么？

像内核线程是由内核自己启动的线程，它们通常被用来操作内存空间，文件系统，延迟操作等。在内核中一共有两种内核线程，一种是用来等待内核中特定操作的，还有一种是检测资源的。它们因为是由内核启动的，因此它们运行在特权模式下，并且直进入内核虚拟地址。

##### 如何运行一个新程序？ --- execve

这个操作和fork函数有本质的区别，它是运行一个新的程序，它需要借助的函数是do_execve函数。

```
int do_execve(char * filename, char __user *__user *argv,
char __user *__user *envp, struct pt_regs * regs)
```

这个函数具体在干什么呢？

首先它会打开一个可执行文件，然后调用函数bprm_init，这个函数处理进程的地址空间，初始化实例和堆栈。结束后会调用prepare_binprm来保存父进程的一些值。最后找到一种二进制执行句柄来执行打开的二进制文件。在这里，程序会释放之前旧进程的所有资源，然后将新的应用映射到一片虚拟地址区域，然后等待被调度。

### 进程调度的具体实现

进程调度主要关心两个事情，一个是调度的法则，一个是进程上下文的切换。

传统的调度法则会给每个进程分配时间片然后让它们执行知道时间片耗完，如果时间片都耗完了就重新计算。但是现在的调度算法只考虑进程的等待时间。

为什么要考虑进程调度的问题，我们知道一个CPU只能最多同时运行一个进程，那么如果有多个任务想要看起来同时执行，那么实际在背后有一个调度者在切换进程，而这对于用户是看不出来的。那么现在计算机如果增加了CPU的数量就能够多跑进程了呀，但是进程数总是可能超过核数，这个问题将无法避免。一个好的调度算法，能够减少不少的等待时间。

那么现代的调度在执行调度时总会挑选等待时间最长的进程，执行的所谓不公平性会分配给所有进程。具体在内核中实现是将所有可以执行的进程在一棵红黑树中排队，根据他们的等待时间。在红黑树中配备一个虚拟的时钟，这个时钟有别于真实的时钟，这个时钟和其中的进程数有关。于是排队的准则按照真实时间-虚拟时间来算。在一个进程开始运行后，它的真实时间会扣去它的运行时间，而虚拟时钟则会继续增加，所以它在运行完后会插入到红黑树较右的位置。

调度实际上会借助许多组件来进行。在进程中有许多成员是和调度有关的：

```
	int prio, static_prio, normal_prio;   //三种优先级，static_prio代表的是进程一开始运行时的优先级，它可以通过nice系统调用设置，但是它在运行时是不能变的。normal_prio是通过static_prio和进程调度法则计算出来的优先级。而调度所看到的优先级存放在prio
	unsigned int rt_priority; //指定为实时调度进程，值为0-99，越低优先级越大
	struct list_head run_list;  //为轮询调度进程设计
	const struct sched_class *sched_class;  //调度单位 
	struct sched_entity se; //这允许群组调度。
	unsigned int policy; //调度法则，在linux2.6中一共有5种法则，SCHED_NORMAL是完全公平调度，SCHED_BATCH,SCHED_IDLE,前面两个实现也是靠完全公平队列。SCHED_RR,SCHED_FIFO
	cpumask_t cpus_allowed; 
	unsigned int time_slice; //为轮询调度进程设计
```

**schedule class**

调度类决定了下一个被调度的任务究竟是谁，调度类根据调度法则有着不同的实现，每个任务会被分配给一个调度类由调度类管理属于它的进程。一个调度类就是许多函数指针。

```
struct sched_class { 
	const struct sched_class *next;   //指向下一个节点，注意的是这种结构已经在编译阶段就定死了，不可能在运行的时候增加结点。
	void (*enqueue_task) (struct rq *rq, struct task_struct *p, int wakeup);  //增加一个可以运行的进程
	void (*dequeue_task) (struct rq *rq, struct task_struct *p, int sleep);   //减少一个可运行的进程
	void (*yield_task) (struct rq *rq);  //脱离处理器
	void (*check_preempt_curr) (struct rq *rq, struct task_struct *p);  //抢占进程
	struct task_struct * (*pick_next_task) (struct rq *rq);   //选择下一个要跑的进程
	void (*put_prev_task) (struct rq *rq, struct task_struct *p);  //在调度下一个进程时将前一个进程移出，但是并不是移出队列
	void (*set_curr_task) (struct rq *rq);  //如果调度法则修改了，修改对应的进程。
	void (*task_tick) (struct rq *rq, struct task_struct *p);  //被periodic调用
	void (*task_new) (struct rq *rq, struct task_struct *p); //与fork挂钩的一个函数
};
```

**run queue**

每一个CPU有自己的队列，一个进程只有可能出现在一个队列中，并且注意的是队列并不是直接管理进程，而是通过调度类来管理。

```
struct rq { 
	unsigned long nr_running;    //队列中的进程数
	#define CPU_LOAD_IDX_MAX 5 
	unsigned long cpu_load[CPU_LOAD_IDX_MAX];   //查看先前的负载
	... 
	struct load_weight load;  //队列的负载
	struct cfs_rq cfs; struct rt_rq rt; //cfs队列和实时调度队列
	struct task_struct *curr, *idle; //curr指向当前执行的进程， idle指向懒惰任务
	u64 clock;
	... 
};
```

**schedule entity**

我个人感觉类似于批处理

```
struct sched_entity { 
	struct load_weight load; 
	/* for load-balancing */ 
	struct rb_node run_node; 
	unsigned int on_rq;
	u64 exec_start; 
	u64 sum_exec_runtime; 
	u64 vruntime; 
	u64 prev_sum_exec_runtime;
	... 
}
```

**priority**

一个普通的进程可以使用nice命令来指定优先级，这个优先级的范围是-20~19。那么在内核看来优先级是0~139的一个数值，其中0~99分配给了实时进程，而普通进程的优先级映射到了100~139。

计算优先级时，prio的计算借助了normal_prio,如果进程不是实时进程，那么它的值就是normal_prio。而在计算normal_prio时如果不是实时进程又直接等于static_pro。这样计算的目的是保证如果某一个进程突然提升了优先级，则当前的优先级还是没有改变。

**load_weight**

这也是计算进程重要性的一个指标。

###### implement

调度的实现主要通过两个函数来实现：periodic scheduler 和 main scheduler。periodic scheduler用函数schedule_tick，它首先获取当前正在运行的cpu，并且更新run queue中的时钟，随后更新cpu_load数组，然后调用sche_class中的task_tick函数。main scheduler用函数schedule()实现，

```
asmlinkage void __sched schedule(void) { 
	struct task_struct *prev, *next; 
	struct rq *rq; int cpu;
need_resched: 
	cpu = smp_processor_id(); 
	rq = cpu_rq(cpu); 
	prev = rq->curr;  //保存之前运行的进程
```

```
if (unlikely((prev->state & TASK_INTERRUPTIBLE) && unlikely(signal_pending(prev)))) { 		prev->state = TASK_RUNNING;  //进程重新变成就绪状态
} else { 
	deactivate_task(rq, prev, 1);  //从队列中去除，调用sche_class中的dequeue
}
```

```
prev->sched_class->put_prev_task(rq, prev);  //调用sche_class中的put_prev_task处理之前的进程
next = pick_next_task(rq, prev);  // 选择下一个要处理的进程
```

```
if (likely(prev != next)) { 
	rq->curr = next; 
	context_switch(rq, prev, next);  //切换进程
}
```

###### context switch

上下文切换主要使用两个函数来实现，switch_mm用来改变进程中的内存上下文，switch_to处理处理器中的寄存器内容和内核堆栈问题。在切换的最后会调用finish_task_switch函数会做一些对现场的清理以及释放一些资源。这个函数将会在switch_to调用后。对于switch_to函数中填写两个参数，一个是切换前的进程，一个是将要切换的进程。这样两个参数看起来是足够的但是思考当一个进程被重新调度，其实它本身是被压入了栈中的，因为在之前的切换的时候又prev指针保存过它。在进入之前的运行情况中会重新刷新prev指针和next指针，这样就会找不到当前执行的这个进程。所以就需要第三个参数macro来保存当前的进程，因此其实调用的形式相当于prev=switch_to(prev, next)。

**最后一点，在进程切换的时候，内核还会用到一个叫做懒FPU 模式的技术，这个技术减少保存浮点寄存器的次数，进而减少开销。**

特殊的两种情况，完全公平调度以及实时调度。

完全公平调度在rq结构中有一个专门的完全公平调度队列，

```
struct cfs_rq { 
	struct load_weight load;   //所有在队列中的负载
	unsigned long nr_running;  //在这个队列中的进程
	u64 min_vruntime;   //这是指队列中虚拟运行时间最短的进程的值
	struct rb_root tasks_timeline;  //红黑树的树根
	struct rb_node *rb_leftmost;   //红黑树最左边的节点
	struct sched_entity *curr;  //指向实体的指针
}
```

**下面开始介绍完全公平调度的调度法则**：

首先来看如何计算虚拟时钟。虚拟时钟会计算一个等待进程到底能在CPU上执行多长时间。计算这个借助函数update_curr,首先这个函数需要更新当前正在运行进程的时钟信息（虚拟运行时间vruntime = 实际运行时间 * 1024/进程权重）；然后就需要设置cfs_rq中的min_vruntime,如果树上有进程那就是最左边的进程的vruntime值，否则取当前进程的vruntime值。进程在红黑树上排序的方法按照自身的虚拟运行时间减去队列中最小虚拟时间。而你会发现，一个正在运行的进程自身的虚拟运行时间是逐步提高的，而睡眠的进程的虚拟运行时间是不变的。（有一个有关延迟的操作没看懂在干嘛。。）

接下去是有关队列的一些操作，如果一个进程需要进入该队列，首先确实需要判断是否这个进程已经在该队列上了，如果不在，那么如果这个进程处于可以执行的状态，只要不是当前正在执行的进程，就可以直接插入树中，当然该进程同样需要调整他的虚拟时间。如果这个进程是睡眠的，则需要通过函数place_entity来确定合适的虚拟执行时间，随后就可以放入红黑树中。

那么如何选择下一个可执行的进程呢？如果没有进程可以运行就立刻返回，否则就去找树上最左边的结点。在确定这个结点要执行时，就要标记它为正在执行的进程，则它会从执行队列中被删除（dequeue），然后去找下一个可能出现的最左结点，但是要注意的是这个进程仍然靠队列中的curr指针指着。

（先跳过 Handling the Periodic Tick ）

当一个进程被唤醒时，它会去查看是否能够抢占当前正在运行的进程。

如果有一个新的进程被创建，一般会考虑它要比它的父进程先执行，这被认为是理所当然的。所以计算完虚拟运行时间后，就算父进程的比子进程的小，也会进行交换，这样子进程就会先执行。

**下面介绍的是实时调度程序：**

对于实时调度的进程，它们的优先级总是比普通的进程高，这样它们总能让调度程序更优先调度它们。在linux系统中有这样两种实时调度类：RR进程和FIFO进程，前者有时间片而后者没有。实时调度的实现比完全公平调度简单很多，因为它们不需要处理像虚拟运行时间这种数据。拥有相同优先级的实时调度程序同样会挂在一个队列上，那么添加或者删除某个进程就只需要在这个优先级队列上进行操作就足够了。对于实时调度程序最主要的是有关它如何处理选择下一个进程和如何处理抢占。在挑选进程时会通过去查找一个bitmap结构去看最高优先级的一个进程，然后移除队列后运行。如果是一个RR进程，则还需要关注时间片的问题，如果时间片被耗尽则需要重新调度。

### 进程调度的加强

之前看到的都是在一个处理器上实现的调度，那么目前的计算机一般支持多处理器，在多处理器的环境下进行进程的调度是否有其他注意点呢？

##### SMP调度

其中有几点是值得注意的：

1. 对于每个CPU其负载情况是要比较均衡的。

2. 一个任务运行在哪个CPU上其实是应该可选择的。

3. CPU间可以完成进程迁移。

完成这种调度，在sche_class结构中需要多增加两个函数：load_balance（可以从最忙的队列中分配任务给当前CPU）和move_one_task（将一个最忙的队列中的进程移动到当前CPU下），这种情况下rq也要多一些值来进行操作：

```
struct rq { 
	... 
	#ifdef CONFIG_SMP 
	struct sched_domain *sd; 
	/* For active balancing */ 
	int active_balance; 
	int push_cpu; 
	/* cpu of this runqueue: */ 
	int cpu;   //代表这个rq属于哪个cpu
	struct task_struct *migration_thread;   //每个rq上有一个迁移线程
	struct list_head migration_queue;  //挂着的是迁移请求
	#endif 
	... 
}
```

所有的执行队列都会组织到一个叫调度域的结构中，这样它们能够共享一些资源。那么来看一下所谓load_balance到底在干嘛：首先这个函数会去寻找哪个处理器上有最多的任务要去跑，这个主要比较队列的负载。如果这个队列上有更多的任务就会调用move_task将该队列上的某些任务迁移到当前的处理器上。如果这种负载均衡的方法失败了，则会唤醒在最忙碌的执行队列上的迁移线程，它实现动态的迁移，这个函数会将某个进程移动到CPU指定的某个rq中，它会去rq的结构中的请求队列中去寻找请求。

内核实现了一种结构叫做调度组，每个组用来存放一些任务。同时还实现了叫做控制组，为了建立任务的虚拟集合。（有什么用我不知道。。。）

最后考虑一些处理多媒体的情况。在之前提到，一般而言在进行系统调用时是不会中断处理的，这样对于一些需要花费很长时间的操作而言是有问题的，这样系统会等待这些长时间的操作，这些操作一般就是多媒体的读写。为了防止这个情况的发生，内核抢占机制诞生了。要注意的一点是，内核的抢占和用户进程的抢占不是一码事。内核抢占要注意操作的原子性，如果处理不当会因为竞态的问题使得数据不一致。通常这个操作是使用自旋锁来进行的，内核在进行一些特定的操作时不能被打断，因此特定空间中只允许一个内核进程执行。