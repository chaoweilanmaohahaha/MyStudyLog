# Angora: Efﬁcient Fuzzing by Principled Search

## Background

普通的随机修改参数的方法似乎缺少了对于上下文的联系，只是通过随便的修改输入，那么对于分支的上下文根本不去关心，所以它的探索是盲目的，这使得在探索的过程中就会缺失许多分支信息

回想一下AFL它对分支的处理机制，它识别某个分支是相当于给每个代码块分配了ID，然后通过对相连的两个ID进行一次hash计算出它在bitmap中的位置。作者认为这样就忽略了输入和分支之间的一些上下文信息。

同时这篇文章的主要的点还在于如何处理特别难推断的分支情况，而使用符号执行的方法去处理太慢，因此作者想通过优化污点追踪的方法，加快原先随机修改的方法，而提出了使用梯度下降算法来推测输入值的措施。

## Design

首先先把握一下这个fuzzer它的具体的工作流程。首先它包括了插入指令和fuzz的一个大循环。那么在这个循环中，angora会选择一个没有被探索的分支然后去找一个输入去继续探索这个分支。首先angora决定了输入的哪几位对这个分支有效所以之后只需要修改这几个字节；随后使用梯度下降的算法去寻找这样一个输入；那么在使用梯度下降算法去搜索的过程中需要克服的几个问题，其中包括可能这几个字节可以组成一个数据类型，所以要推断出数据类型；并且有的情况下，太短的输入并不能触发分支，所以要适当扩展输入。

### 上下文相关的分支计数

AFL的分支覆盖是基于一种上下文不敏感的策略，也就是说只要你在一次执行中走过了某些路径，那么在下次执行中就算走的顺序不同，但是他也会认为这并不感兴趣，所以就会放弃继续探测，但往往这样也会存在漏洞。

那么作者思考如何使它带上上下文，如果我们将AFL中的路径定义为一个二元组<lprev,lcur>，那么在这篇文章中作者将路径写为三元组<lprev, lcur, context>，其中context代表的就是上下文信息。context  = h(stack)，其中h代表一个hash函数，而stack指的是函数调用的栈状态。

但是如果直接这么加有个问题出现在走循环或者递归中，现在的实现主要是选择了一个特殊的hash函数，使用了异或，那么此时使得h(stack)最多只会算两次。

### 字节级别的污点追踪

这是针对某个没有被探测到的分支进行的操作。但是污点追踪本身是比较费事的，况且还要提供一种字节级别的污点追踪，所以希望污点追踪并不会贯穿于整个运行中，那么在某一次运行时确定了污点位置，之后的修改后就不会带着污点信息运行了。

首先作者思考如何存储污点标记，那么最后选择使用一个表来存储bit向量代表了污点的标记，这样可以尽可能地减少记录污点的空间。并且定义了三个功能：

* insert：插入某一个bit向量b
* find：找到某个标记的向量t
* union：合并两个污点标记

合并操作尤为繁琐，需要计算两个bit向量表的交集，并且保证表中这个交集是否已经有了，如果没有就加入它。但是要想办法去更快地寻找。那么作者提出了一个新的数据结构来存储。对于每一个向量，它都有一个独特地标签，那么当插入某一个向量地时候就会颁发下一个标签，那么使用一个二叉树来映射所有的向量，每一个树结点代表某个向量。那么这棵树怎么遍历呢？它需要一位一位去看，如果某一位是0则走左孩子，某一位是1走右孩子。而这个标签又映射了表格的系数。

作者根据一些特殊情况，还对插入算法进行了修改，最后进行了剪枝。

### 梯度下降寻找值

使用了上面的字节级别追踪后，我们已经获得了在输入中到底哪些字节影响了这个分支，现在思考的是选择什么修改机制去获取输入。

作者认为这是一个典型的搜索问题，采用梯度下降的算法。现在把问题划归为对于一个fx的限制问题，其中x是一个向量，而这个限制只有可能有三种：

* fx < 0
* fx <=0
* fx == 0

那么具体是怎么做的呢？就是用了梯度下降的算法。但是梯度下降算法有时会落入局部最优的情况，对fuzz来说就没问题，我们只是想找到一个足够好的值就行了。

### 类型判断

在做梯度下降的时候会存在问题，如果确实是一个字节一个字节可能没问题，但是有的时候会让四个字节组成一个 整数，然后对这个整数一起改变，那么此时我们不能把每个字节都认为是向量中的一个单独元素，否则会产生偏差。

为了解决这个问题，所以我们必须确定：

* 在输入中哪些字节总是会一起称为一个类型
* 到底这个是什么类型

我们把第一个问题叫做**形式推测**，第二个叫做**类型推测**。对于第一个，如果它在运行是被读到了一个基本类型中，那么就给这类字节打上标记，就知道这些字节一般一起用（取最小）。那么对于第二个就需要用到执行指令时的语义了，那么使用这些字节操作的指令用来操作什么就认为这些字节属于什么类型。

### 输入长度修改

对于很多fuzzer来说，开始的输入一般越小越好。那么如果一些分支就是要求输入长度超过某个阈值。但是这对于fuzzer是一个两难的问题，如果过长又会让fuzzing的效率下降。

在污点跟踪时，`Angora`把read相关函数调用的目标内存地址和相关的字节偏移相关联，同时也记录read调用的返回值，如果返回值在条件语句中使用且约束不满足，则`Angora`增加输入长度。



## evaluation

### 和其他的一些fuzzer来做对比

对比的指标是它们寻找bug的能力，使用的还是LAVA这个数据集。作者使用了如下的一些fuzzer进行对比：FUZZER and RES， VUzzer， Steelix， AFL 2.51b。然后做了实验发现，AFL最差，Steelix是第二号的，而Angora是最好的，比第二名要好很多，他几乎发现了所有的问题。

作者也分析了，因为LAVA中很多都使用了magic bytes去保护bug分支。

### 用angora去评估没修改过的现实程序

因为考虑到了现实世界中的程序只会又很少的错误，那么除了考量发现的bug数，还要考虑代码覆盖情况。那么作者使用了gcov来记录了分支覆盖的情况。作者使用了afl进行对比实验发现，在覆盖上提高了127.4，分支覆盖提高144。那么显然因为angora可以评测两边的比较复杂的分支。

### 单独评估各个技术的优势

#### 上下位依赖推断

使用了使用这个技术的和没使用这个技术的两个不同的fuzzer进行对比，发现使用了之后明显覆盖了更多的分支。那么这个会带来一个问题，就是hash碰撞会增加，所以就需要增加bitmap的大小。

#### 梯度下降测值

用这个技术和随机修改进行比较，可以发现梯度下降后可以解析出更多的一些限制条件，所以效率更高。

#### 长度推测

和AFL和其他不同的fuzzer的策略进行比较，主要考量1、使用这种策略需要多少次的增长？2、有用的输入的平均长度是多少？

测试显示angora使用了2的指数倍少的变化次数，并且发现了更多有用的输入。

### 执行速度

angora确实因为牺牲了执行速度来发现更多的分支，并且生成了更多有用的输入。